#   ex  d   sisdr_test
163 0.0 0.0 15.954
183 0.1 0.1 15.923
184 0.3 0.3 15.915
185 1.0 1.0 15.902
188 3.0 3.0 15.832
189 3.0 3.0 15.811
190 3.0 3.0 15.875
191 10  10  15.614
192 30  30  15.915
195 100 100 15.971
196 10  0.0 training failed
197 10  0.0 15.924
199 0.0 10  15.948
200 -10 0.0 15.862
201 0.0 -10 training failed
242 0.0 -10 16.019
243 0.0 -10 training failed
246 0.0 -10 15.848


b in D_b  =>  eval(m1, b) ~ N(15.9, 6)
b in D_b  =>  eval(m2, b) ~ N(15.8, 7)
T = {b1, .., bn} ~ D_b^n
n = 375
eval(m1, T) ~ N(15.9, 6/sqrt(n)) = N(15.9, 0.3^2)
eval(m2, T) ~ N(15.8, 7/sqrt(n)) = N(15.8, 0.35^2)
eval(m1, T) = eval(m2, T) + eps


after critical bug fix:
258 1e-2  0.0 0.0 12.915   4 epochs, since no progress
260 1e-3  0.0 0.0 12.915   6 epochs

plain sepdiff:
262 1e-3  2       12.806
plain sepformer:
267       -       12.839    audio totally fine
plain sepformer+diffusion:
272       -       -30.062
baseline:
274 1e-2  8 0.999   6   12.930
275 1e-1  8 0.999   1   -24.461
276 1e-3  8 0.999   1   12.853
292 1e-3  8 0.999   6   12.932
293 1e-2  4 0.9993  20  12.951
294 1e-3  8 0.999   6   12.916

bayesian exps (1e-3  8 0.999   6):
299   0.0   0.0   12.928
301   1.0   0.0   12.937
302   3.0   0.0   12.912
303   10.0  0.0   12.895
304   0.0   1.0   12.909
305   0.0   3.0   10.202
313   0.0   10.0  10.743
315   1.0   0.0   12.848
318   0.3   0.0   9.818
319   0.0   0.3   12.927
320   0.1   0.0   -23.924
321   0.0   0.1   12.915
327   0.3   0.0   12.926
328   0.1   0.0   12.939
330   -3.0  0.0   12.869
331   0.0   -1.0  12.887
338   0.0   -1.0  12.306
339   0.0   0.0   12.836  1 epoch only

bs 8->4 probably somewhere here, unfortunately this transition is not recorded

3sp exps (same hparams):
368   0.0   0.0   8.305   sounds good!
372   1.0   0.0   9.717
373   0.0   1.0   9.692
374   0.0   0.0   9.713
375   3.0   0.0   9.707
379   0.0   3.0   9.699
380   0.3   0.0   9.708
381   0.0   0.3   9.720
382   -1.0  0.0   9.704
384   0.0   -1.0  9.699
390   10.0  0.0   9.166
414   0.0   0.0   9.709   epoch len 3000->1500, gamma .99995, lr 3e-3
415   0.0   0.0   9.699   epoch len 500.
416   0.0 -10.0   9.650   epoch len 500
wtf why -10.. checkout back and rerun

5sp exps (3e-3  4 .99998  6 500):
429   0.0   0.0   -13.568

5sp sepformer only:
443               4.068

5sp exps (3e-3  4 .9994  3 1000):
449   0.0   0.0   4.305
451   1.0   0.0   4.297
(3e-3   1 .9991 3 2000)
                  sisdr pesq  stoi
513   0.0   0.0   4.283 1.193 0.428
514   1.0   0.0   4.268 1.185 0.426
515   0.0   1.0   4.285 1.189 0.428
516   0.0   3.0   4.295 1.190 0.428
517   3.0   0.0   4.282 1.188 0.427
520   10.0  0.0   4.280 1.190 0.428
543   0.0   10.0  4.256 1.187 0.428
550   -1.0  0.0   4.236 1.182 0.428
564   0.0   -1.0  4.260 1.183 0.428

awaiting for 3sp:  0.0   10.0  

5sp cont, new code from 10sp:
565   0.0   0.0   ~4, not waited till the end
585   0.0   0.0   ~4, now waited till the end
10sp!:
587   0.0   0.0   -4.251  1.115 0.506
588   1.0   0.0   -4.240  1.113 0.506
589   0.0   1.0   -4.218  1.113 0.508
590   3.0   0.0   -4.236  1.114 0.507
591   0.0   3.0   -4.228  1.113 0.507
592   0.0   0.0   -4.236  1.114 0.507
593   10.0  0.0   -4.388  1.113 0.503
594   0.0   1.0   -4.238  1.113 0.506
595   0.0   10.0  -4.254  1.116 0.506
596   0.3   0.0   -4.263  1.116 0.505
597   0.0   0.3   -4.225  1.113 0.508
598   -1.0  0.0   -4.243  1.114 0.506
632   0.0   -1.0  -4.234  1.113 0.506
      c1    c2    c3
668   0.0   0.0   0.1   -4.248  1.115 0.505
669   0.0   0.0   10.0  -4.251  1.115 0.505
train epoch 2k->200, val 1k->100, gamma .9991->.991:
/10 again:
678   0.0   0.0   10.0  -5.096  1.126 0.477
679   0.0   0.0   10.0  -4.943  1.109 0.482
680                     -4.695  1.104 0.501 sepformer only
681                     -4.695  1.104 0.501 sepformer only
#682               100   -5.069  1.113 0.476
#683               1e3   -4.845  1.103 0.486
#684               1e3   -4.803  1.107 0.493
#685               1e3   -4.784  1.106 0.489
#686               0     -12.130 1.122 0.411
#688               0     -4.800  1.100 0.486
#689               0     -5.082  1.118 0.480
#690               1e4   -5.174  1.128 0.478
#691               1e4   -5.048  1.108 0.477
#692               1e4   -27.730 1.146 0.306
#693               1e5   -4.861  1.114 0.491
#694               1e5   
#695               1e5   -4.849  1.118 0.491
#696               1e5   -4.953  1.118 0.488
#697               1e5   -25.894 1.147 0.283
#698               1e5   -5.021  1.116 0.489
#699               1e5   -4.893  1.112 0.490
#700               1e6   -4.993  1.110 0.494
#701               1e6   -4.907  1.116 0.491
#702               1e7   -5.012  1.119 0.493
705               0.1   -26.017 1.242 0.285
706               0.1   -26.626 1.140 0.294
707               0.1   -4.838  1.097 0.483
708               0.1   -4.957  1.124 0.480
709               0.1   -4.749  1.131 0.488
710               0.1   -4.908  1.112 0.482
711               0.1   -4.773  1.113 0.484
712               0.1   -4.838  1.114 0.484
713               0.1   -4.861  1.111 0.482
714               0.3   -5.242  1.122 0.479
715               0.3   -4.929  1.122 0.484
716               0.3   -17.581 1.134 0.371
717               0.3   -4.786  1.116 0.489
718               1.0   -4.758  1.119 0.486
719               1.0   -4.883  1.127 0.478
implemented ">=1" restriction
728               1.0   -4.983  1.109 0.480
730               0.3   -4.901  1.122 0.478   invalid
732               0.1   -4.833  1.110 0.488   invalid
733               0.1   -4.839  1.136 0.487   invalid
736               0.3   -5.071  1.116 0.476
737               0.1   -4.997  1.113 0.485
738               3.0   -4.730  1.103 0.488
739               3.0   -5.079  1.098 0.481
740               10.0  -4.878  1.113 0.490
train len 20->60, val 10->30, gamma .91->.97
741               0.0   -4.358  1.111 0.501
742               0.0   -4.316  1.118 0.501
743               1.0   -4.362  1.110 0.501
744               3.0   -4.368  1.115 0.503
745               0.3   -4.348  1.109 0.501
746               0.1   -4.329  1.108 0.502

#add two convs
#749                     -16.403 1.089 0.335
#750                     -27.720 1.088 0.293
#751                     -17.950 1.111 0.347
#752                     -15.981 1.099 0.344
#add skip connection
#753               0.0   -4.750  1.116 0.492
#754               0.0   -5.088  1.109 0.479
#758               0.0   -25.287 1.131 0.316
#759               0.0   -4.358  1.116 0.501
#back to 200 100 .991 (config-200.json):
#755                     -25.792 1.142 0.293
#756                     -4.423  1.112 0.498   with skip-connections
#757                     -4.110  1.109 0.510   without skip-connections
#config-2k:
#762                     -25.224 1.131 0.350   with sc
#763                     -4.304  1.116 0.504   without sc
#764                     -4.516  1.114 0.498   with sc
#config-200:
#766                     -4.685  1.113 0.492   with sc
#convs discovered to only affect sepformer output, not denoiser( moreover, it was inside NO_GRAD!..
config-60:
with convs:
771                     -19.468
772                     -4.371
without convs:
773                     -4.364
774                     -26.347
unet instead of convs:
779                     -4.340
780                     -4.348
no convs/unets:
781                     -25.295
782                     -4.371
783                     -4.350
784                     -4.419
785                     -25.442
786                     -4.360
unet back:
787                     -4.320
788                     -4.347
789                     -4.351
790                     -4.339
791                     -4.332
792                     -4.432
increase unet:
config-60:
794                     -4.404
795                     -4.372
796                     -4.389
config-700:
797                     -4.241
config-200:
798                     -4.132
799                     -4.157
800                     -4.139
still config-200, but no unet:
803                     -4.136
2k:
805                     -4.238
still 2k, but with unet:
806                     -4.206
config-200:
807                     -4.152
no unet:
809                     -4.110
810                     -4.122
811                     -4.123
812                     -4.119
813                     -26.013
814                     -4.118
config-700:
815                     -11.090
816                     -4.261
817                     -4.228
with unet again:
818                     -4.246
819                     -4.257
820                     -4.232
config-60, small unet:
824                     -25.697
825                     -4.371
826                     -4.428
no net:
828                     -26.433
829                     -4.353
830                     -14.555
831                     -24.228
832                     -4.329
833                     -4.354
834                     -4.377
835                     -4.368
836                     -4.349
837                     -25.910
838                     -4.342
839                     -4.321
840                     -4.392
841                     -4.330
842                     -4.319
843                     -4.323
844                     -4.329
small unet back:
845                     -4.412
846                     -4.420
847                     -4.405
848                     -4.422
849                     -4.770
850                     -4.372
config-2k:
852                     -4.215  with large unet
853                     -4.233  with nothing
config-60, large unet with fixed strides:
889                     -4.395
890                     -4.365
config-200:
895                     -4.163
config-700:
897                     -4.263
remove batchnorm in the end, config-60:
900                     -26.576
901                     -4.473
config-200:
902                     -4.137
unet for fusion:
925                     -8.323
927                     -16.735
config-200:
928                     -4.385
config-60:
933                     -4.806
934                     -6.943
doubly deep, config-200:
940                     -4.140
with features from sepformer:
954                     -4.139  impaired unet upsampling, didn't receive gmids
config-2k:
970                     -4.225
